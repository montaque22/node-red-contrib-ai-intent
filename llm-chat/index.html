<style>
    .disabled{
        opacity: .5;
        pointer-events: none;
    }
</style>
<script type="text/javascript">
    (() => {
        const TOOL_CHOICE = [
            { value: "none", label: "None" },
            { value: "auto", label: "Automatic" },
            { value: "required", label: "Required" }
        ]

        const removeDuplicates = (data) => {
            const intents = {}
            const tools = []

            data
                .forEach((intent => {
                if (intent.type === "OpenAI Tool") {
                    if (!intents[intent.name]) {
                        intents[intent.name] = true
                        tools.push(intent)
                    }
                } else {
                    tools.push(intent)
                }
            }))

            return tools
        }

        $.getJSON('registered-intents', function (data = RED.settings.callIntentRegistry) {
            const tools = removeDuplicates(data)
            window.__tools =   getToolOptions(tools)
            initialize()
        });

        const getToolOptions = (intents = []) => {
            return intents
                .map(intent => {

                if(intent.type === "Register Intent"){
                    return { value: intent.name, label: `${intent.name} (Registered Intent)`}
                }else {
                    const tool = JSON.parse(intent.tool)
                    return { value: tool.function.name, label: `${intent.name} (Tool Node)`}
                }
            })
        }

        const cleanUpEditor = (scope, property) => {
            scope[property].destroy();
            delete scope[property]
        }

        const createEditor = (value, id) => {
           return  RED.editor.createEditor({
                id: id,
                mode: "ace/mode/nrjavascript",
                value:value,
                globals: {
                    msg: true,
                    context: true,
                    RED: true,
                    util: true,
                    flow: true,
                    global: true,
                    console: true,
                    Buffer: true,
                    setTimeout: true,
                    clearTimeout: true,
                    setInterval: true,
                    clearInterval: true,
                },
            });
        }

        RED.nodes.registerType("LLM Chat", {
            category: 'AI Intent',
            color: '#1abc9c',
            icon:"bot-message-square.svg",
            defaults: {
                name: { value: "" },
                platform: { value: "", type: "platform-configuration", required: false },
                tools: {value: ""},
                tool_choice: {value: "none"},
                conversation_id: {value: ""},
                user: {value: ""},
                system: {value: ""},
                historyLimit: {value: 7}
            },
            inputs: 1,
            outputs: 1,
            paletteLabel: "LLM Chat",
            label: function () {
                return this.name || "Chat";
            },

            oneditprepare: function(){
                // tabs
                var tabs = RED.tabs.create({
                    id: "tabs",
                    onchange: function (tab) {
                        $("#tabs-content").children().hide();
                        $("#" + tab.id).show();
                    },
                });

                tabs.addTab({
                    id: "tab-system",
                    iconClass: "fa fa-cog",
                    label: 'System Prompt',
                });

                tabs.addTab({
                    id: "tab-user",
                    iconClass: "fa fa-user",
                    label: 'User Prompt',
                });

                // editor
                this.systemEditor = createEditor(this.system, "node-input-system-editor")
                this.userEditor = createEditor(this.user, "node-input-user-editor")

                $("#node-input-historyLimit").typedInput({
                    type:"num",
                    types:["num"],
                    typeField: "#node-input-historyLimit-type"
                })

                $("#node-input-conversation_id").typedInput({
                    type:"str",
                    typeField: "#node-input-conversation_id-type"
                })

                $.getJSON('registered-intents', function (data = RED.settings.callIntentRegistry) {
                    const tools = removeDuplicates(data)
                    window.__tools = getToolOptions(tools)

                    $("#node-input-tools").typedInput({
                        types: [
                            {
                                value: "",
                                multiple: true,
                                options: window.__tools
                            }
                        ]
                    })
                });
                $("#node-input-tool_choice").typedInput({
                    types: [
                        {
                            value: "",
                            options: TOOL_CHOICE
                        }
                    ]
                }).on("change", function() {
                    if ($(this).val() === "none") {
                        $("#tools").addClass("disabled");
                    } else {
                        $("#tools").removeClass("disabled");
                    }
                })
            },

            oneditsave: function () {
                this.system = this.systemEditor.getValue();
                this.user = this.userEditor.getValue();
                cleanUpEditor(this, "systemEditor")
                cleanUpEditor(this, "userEditor")
            },
            oneditcancel: function () {
                cleanUpEditor(this, "systemEditor")
                cleanUpEditor(this, "userEditor")
            },
        });
    })()

</script>

<script type="text/html" data-template-name="LLM Chat">

    <div style="display: flex; justify-content: center; margin-bottom: 25px;">
        <a href="https://youtu.be/2Efb1X6F5UY" target="_blank" referrerpolicy="no-referrer"
           style="color: #f53b57"><i class="fa fa-youtube"></i><span style="padding-left: 10px;">Watch
           LLM Chat Node Tutorial</span></a>
    </div>

    <div class="form-row">
        <label for="node-input-name"> Name</label>
        <input type="text" id="node-input-name" placeholder="Name">
    </div>

    <div class="form-row">
        <label for="node-input-platform"> Configuration</label>
        <input type="text" id="node-input-platform" placeholder="0a1b2c3b4d5e6f">
    </div>


    <div class="form-row">
        <label for="node-input-conversation_id"> Conversation Id</label>
        <input type="text" id="node-input-conversation_id">
    </div>
    <div class="form-row">
        <label for="node-input-historyLimit">History Limit</label>
        <input type="text" id="node-input-historyLimit" placeholder="7">
    </div>

    <div class="form-row">
        <label for="node-input-tool_choice">Tool Choice</label>
        <input type="text" id="node-input-tool_choice">
    </div>

    <div class="form-row" id="tools">
        <label for="node-input-tools"> Tools</label>
        <input type="text" id="node-input-tools">
    </div>

    <div class="form-row tabs-row">
        <ul style="min-width: 600px; margin-bottom: 20px;" id="tabs"></ul>
    </div>

    <div id="tabs-content" style="min-height: calc(100% - 95px);">
        <div id="tab-system" style="display:none">
            <div class="form-row node-text-editor-row" style="position:relative">
                <div
                        style="height: 450px; min-height:150px;"
                        class="node-text-editor"
                        id="node-input-system-editor"
                ></div>
            </div>
        </div>


        <div id="tab-user" style="display:none">
            <div class="form-row node-text-editor-row" style="position:relative">
                <div
                        style="height: 450px; min-height:150px;"
                        class="node-text-editor"
                        id="node-input-user-editor"
                ></div>
            </div>
        </div>
    </div>
   
</script>

<script type="text/html" data-help-name="LLM Chat">
    <p>Calls a Large Language Model (LLM) like ChatGPT, Gemini, or Ollama, using dynamic user/system prompts and optional tool functions. Returns the modelâ€™s response in <code>msg.payload.response</code>.</p>

    <h3>Important</h3>
    <p>To use this node, you must configure a valid platform connection (ChatGPT, Gemini, or Ollama). Refer to the setup documentation for your chosen provider. Not all platforms support function calling.</p>

    <h3>Inputs</h3>
    <dl class="message-properties">
        <dt><code>msg.payload</code> <span class="property-type">object</span></dt>
        <dd>
            <p>The primary input to the LLM. It should include:</p>
            <ul>
                <li><code>user</code>: The prompt/question you want to send (required)</li>
                <li><code>system</code>: Instructions for how the LLM should behave (optional)</li>
            </ul>
            <p>Example:</p>
            <pre>
msg.payload = {
  system: "You are a helpful assistant.",
  user: "What is the capital of Alaska?"
};
      </pre>
        </dd>

        <dt><code>msg.payload.options</code> <span class="property-type">object</span></dt>
        <dd>
            Optional. Allows advanced LLM settings such as <code>temperature</code>, <code>max_tokens</code>, <code>format</code>, etc. Platform-dependent.
            <pre>
msg.payload = {
  user: "What is capital of Alaska. Respond in JSON.",
  options: {
    format: "json" // e.g., for Ollama
  }
};
      </pre>
        </dd>

        <dt><code>msg.clearChatHistory</code> <span class="property-type">boolean</span></dt>
        <dd>If set to <code>true</code>, clears all stored messages associated with the configured <code>Conversation Id</code>.</dd>
    </dl>

    <h3>Outputs</h3>
    <dl class="message-properties">
        <dt><code>msg.payload.response</code> <span class="property-type">string</span></dt>
        <dd>The LLM-generated response based on the input prompt and context.</dd>

        <dt><code>msg.payload.tool_call</code> <span class="property-type">object</span></dt>
        <dd>(If applicable) Details about any tool or function the model called.</dd>

        <dt><code>msg.payload.usage</code> <span class="property-type">object</span></dt>
        <dd>May include token usage or cost data, depending on the LLM platform.</dd>
    </dl>

    <h3>Node Configuration</h3>
    <dl>
        <dt>Conversation Id <span class="property-type">string</span></dt>
        <dd>
            Used to group and persist conversations across messages. Shared IDs connect message history across nodes. If omitted, the conversation is treated as isolated.
        </dd>

        <dt>History Limit <span class="property-type">number</span></dt>
        <dd>
            Sets how many previous messages are remembered for context. Only used if <code>Conversation Id</code> is provided. Default is 7.
        </dd>

        <dt>Tool Choice <span class="property-type">dropdown</span></dt>
        <dd>
            Determines whether function tools are used:
            <ul>
                <li><code>None</code>: No tools will be made available to the LLM</li>
                <li><code>Automatic</code>: LLM may choose to use tools</li>
                <li><code>Required</code>: LLM must use one of the selected tools</li>
            </ul>
        </dd>

        <dt>Tools <span class="property-type">string</span></dt>
        <dd>
            This dropdown lists all available functions from registered intents or tool nodes. These are passed to the LLM if Tool Choice is not <code>None</code>.
        </dd>
    </dl>

    <h3>System and User Prompts</h3>
    <p>You can define both prompts using the built-in JavaScript editors under the "System" and "User" tabs. These are executed at runtime using:</p>
    <pre>
return `Hello ${msg.topic}`
  </pre>
    <p>Each editor runs inside a secure sandbox with access to:</p>
    <ul>
        <li><code>msg</code></li>
        <li><code>context</code></li>
        <li><code>flow</code></li>
        <li><code>global</code></li>
    </ul>
    <p><strong>Important:</strong> You must return a string. The returned values are used as the actual prompts sent to the LLM.</p>

    <p>If <code>msg.payload.user</code> or <code>msg.payload.system</code> are provided at runtime, they will override the prompt editors.</p>

    <h3>Supported Platforms</h3>
    <ul>
        <li><strong>ChatGPT</strong> â€“ via OpenAIâ€™s API</li>
        <li><strong>Gemini</strong> â€“ via Googleâ€™s AI platform</li>
        <li><strong>Ollama</strong> â€“ for local/private models (model compatibility may vary)</li>
    </ul>

    <h3>Status</h3>
    <ul>
        <li><span style="color:green;">Green ring</span>: Working</li>
        <li><span style="color:red;">Red dot</span>: Error occurred</li>
        <li><span style="color:gray;">Gray dot</span>: Complete</li>
    </ul>

    <h3>Example Use Cases</h3>
    <ul>
        <li>Conversational assistants with memory</li>
        <li>Tool-enhanced AI workflows (e.g., calculations, scheduling)</li>
        <li>Multi-platform AI interactions with dynamic behavior</li>
    </ul>

    <p>
        <strong>Need help?</strong>
        <a href="https://youtu.be/2Efb1X6F5UY" target="_blank" rel="noreferrer noopener">
            Watch the LLM Chat Node Tutorial
        </a>
    </p>
</script>
